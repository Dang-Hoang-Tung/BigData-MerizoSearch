- name: Install and configure Hadoop on all nodes
  hosts: all
  vars_files:
    - variables.yaml
  tasks:
    - name: Download Hadoop
      ansible.builtin.get_url:
        url: "{{ hadoop_download_url }}"
        dest: "{{ hadoop_archive_file_path }}"
    - name: Delete Hadoop home directory
      ansible.builtin.file:
        path: "{{ hadoop_home_dir }}"
        state: absent
    - name: Unpack Hadoop tgz file
      ansible.builtin.unarchive:
        src: "{{ hadoop_archive_file_path }}"
        dest: "{{ working_dir }}"
        creates: "{{ hadoop_home_dir }}"
        remote_src: true
        extra_opts:
          - --transform
          - "s/^hadoop[a-zA-Z0-9._-]*/{{ hadoop_home_dir_name }}/"
    - name: Set Hadoop environment variables
      ansible.builtin.blockinfile:
        path: "{{ working_dir }}/.bashrc"
        block: |
          export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:bin/java::")
          export HADOOP_HOME={{ hadoop_home_dir }}
          export HADOOP_INSTALL=$HADOOP_HOME
          export YARN_HOME=$HADOOP_HOME
          export PATH=$PATH:$HADOOP_INSTALL/bin:$HOME/{{ spark_home_dir_name }}/bin
          export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
          export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
          export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
          export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HADOOP_HOME/lib/native
        state: present
    - name: config core-site.xml
      ansible.builtin.blockinfile:
        path: "{{ hadoop_config_dir }}/core-site.xml"
        insertafter: <configuration>
        marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
        block: |
          <property>
              <name>fs.default.name</name>
              <value>hdfs://mgmtnode:9000/</value>
          </property>
          <property>
              <name>fs.default.FS</name>
              <value>hdfs://mgmtnode:9000/</value>
          </property>
        state: present
    - name: config hdfs-site.xml
      ansible.builtin.blockinfile:
        path: "{{ hadoop_config_dir }}/hdfs-site.xml"
        insertafter: <configuration>
        marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
        block: |
          <property>
              <name>dfs.datanode.data.dir</name>
              <value>{{ hdfs_datanode_dir }}</value>
              <final>true</final>
          </property>
          <property>
              <name>dfs.namenode.name.dir</name>
              <value>{{ hdfs_namenode_dir }}</value>
              <final>true</final>
          </property>
          <property>
              <name>dfs.replication</name>
              <value>1</value>
          </property>
        state: present
    - name: config yarn-site.xml
      ansible.builtin.blockinfile:
        path: "{{ hadoop_config_dir }}/yarn-site.xml"
        insertafter: <configuration>
        marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
        block: |
          <property>
              <name>yarn.resourcemanager.resource-tracker.address</name>
              <value>mgmtnode:8025</value>
          </property>
          <property>
              <name>yarn.resourcemanager.scheduler.address</name>
              <value>mgmtnode:8035</value>
          </property>
          <property>
              <name>yarn.resourcemanager.address</name>
              <value>mgmtnode:8050</value>
          </property>
          <property>
              <name>yarn.log-aggregation-enable</name>
              <value>true</value>
          </property>
        state: present
    - name: config mapred-site.xml
      ansible.builtin.blockinfile:
        path: "{{ hadoop_config_dir }}/mapred-site.xml"
        insertafter: <configuration>
        marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
        block: |
          <property>
              <name>mapreduce.job.tracker</name>
              <value>mgmtnode:5431</value>
          </property>
          <property>
              <name>mapred.framework.name</name>
              <value>yarn</value>
          </property>
          <property>
              <name>yarn.app.mapreduce.am.env</name>
              <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
          </property>
          <property>
              <name>mapreduce.map.env</name>
              <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
          </property>
          <property>
              <name>mapreduce.reduce.env</name>
              <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
          </property>
        state: present
    - name: fix JAVA_HOME in Hadoop Env script
      ansible.builtin.blockinfile:
        path: "{{ hadoop_config_dir }}/hadoop-env.sh"
        insertafter: "# export JAVA_HOME="
        block: |
          export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:bin/java::")
        state: present

- name: Configure hdfs on worker nodes
  hosts: workergroup
  vars_files:
    - variables.yaml
  tasks:
    - name: Create datanode folder
      ansible.builtin.file:
        path: "{{ hdfs_datanode_dir }}"
        state: directory

- name: Configure hdfs on mgmt node
  hosts: mgmtgroup
  vars_files:
    - variables.yaml
  tasks:
    # - name: Delete namenode folder
    #   ansible.builtin.file:
    #     path: "{{ hdfs_namenode_dir }}"
    #     state: absent
    - name: Create namenode folder
      ansible.builtin.file:
        path: "{{ hdfs_namenode_dir }}"
        state: directory
    - name: Generate workers file
      ansible.builtin.template:
        src: files/workers.j2
        dest: "{{ hadoop_config_dir }}/workers"
    - name: Format hdfs cluster
      ansible.builtin.shell: hdfs namenode -format
